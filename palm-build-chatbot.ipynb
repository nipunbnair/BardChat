{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# About PaLM API"],"metadata":{"id":"_uVT3TQ7sMY7"}},{"cell_type":"markdown","metadata":{"id":"Tce3stUlHN0L"},"source":["##### Copyright 2023 Google LLC."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"tuOe1ymfHZPu"},"outputs":[],"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."]},{"cell_type":"markdown","metadata":{"id":"gQnbmB70zqon"},"source":["**Note**: At this time, the PaLM API is [only available in certain regions](https://developers.generativeai.google/available_regions)."]},{"cell_type":"markdown","source":["# Chatbot w/ Bard API"],"metadata":{"id":"ib1AG4FukFEA"}},{"cell_type":"markdown","source":["## Setup Environment"],"metadata":{"id":"OaGoxClLXoP6"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5kK_XBJ1XHGh","colab":{"base_uri":"https://localhost:8080/","height":581},"executionInfo":{"status":"ok","timestamp":1694761987521,"user_tz":-330,"elapsed":7141,"user":{"displayName":"Gopal Sharma","userId":"12839894256006393174"}},"outputId":"a9f3fa98-c638-47e6-8d26-6309262521a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting google-generativeai\n","  Downloading google_generativeai-0.1.0-py3-none-any.whl (122 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/122.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting google-ai-generativelanguage==0.2.0 (from google-generativeai)\n","  Downloading google_ai_generativelanguage-0.2.0-py3-none-any.whl (113 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.3/113.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.2.0->google-generativeai) (2.11.1)\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.2.0->google-generativeai) (1.22.3)\n","Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.2.0->google-generativeai) (3.20.3)\n","Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.2.0->google-generativeai) (1.60.0)\n","Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.2.0->google-generativeai) (2.17.3)\n","Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.2.0->google-generativeai) (2.31.0)\n","Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.2.0->google-generativeai) (1.57.0)\n","Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.2.0->google-generativeai) (1.48.2)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.2.0->google-generativeai) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.2.0->google-generativeai) (0.3.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.2.0->google-generativeai) (1.16.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.2.0->google-generativeai) (4.9)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.2.0->google-generativeai) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.2.0->google-generativeai) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.2.0->google-generativeai) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.2.0->google-generativeai) (2023.7.22)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.2.0->google-generativeai) (0.5.0)\n","Installing collected packages: google-ai-generativelanguage, google-generativeai\n","Successfully installed google-ai-generativelanguage-0.2.0 google-generativeai-0.1.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]}}},"metadata":{}}],"source":["!pip install google-generativeai"]},{"cell_type":"code","source":["import google.generativeai as palm\n","import os\n","import time"],"metadata":{"id":"VF1KrU4urUJP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Grab an API Key\n","\n","To get started, you'll need to [create an API key](https://developers.generativeai.google/tutorials/setup)."],"metadata":{"id":"GJ7HQfpqs905"}},{"cell_type":"code","source":["palm.configure(api_key='INSERT_KEY_HERE')"],"metadata":{"id":"-rY42uSnXbOG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Use the palm.list_models function to find available models:\n","models = [m for m in palm.list_models() if 'generateText' in m.supported_generation_methods]\n","model = models[0].name\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Yz70ZNltkdy","executionInfo":{"status":"ok","timestamp":1694762523170,"user_tz":-330,"elapsed":422,"user":{"displayName":"Gopal Sharma","userId":"12839894256006393174"}},"outputId":"30c2a4c8-7af9-4aa7-99f4-26a491e53255"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["models/text-bison-001\n"]}]},{"cell_type":"markdown","source":["## Simplest Chatbot"],"metadata":{"id":"SQW9eevUj8ly"}},{"cell_type":"code","source":["prompt = \"\"\"\n","You are an expert at solving word problems.\n","\n","Solve the following problem:\n","\n","I have three houses, each with three cats.\n","each cat owns 4 mittens, and a hat. Each mitten was\n","knit from 7m of yarn, each hat from 4m.\n","How much yarn was needed to make all the items?\n","\n","Think about it step by step, and show your work.\n","\"\"\"\n","\n","completion = palm.generate_text(\n","    model=model,\n","    prompt=prompt,\n","    temperature=0,\n","    # The maximum length of the response\n","    max_output_tokens=800,\n",")\n","\n","print(completion.result)"],"metadata":{"id":"EtkLIA_FttPG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set your input text\n","# prompt = \"Why is the sky blue?\"\n","prompt = \"What is Quantum Computing? Explain like I'm 5.\"\n","\n","completion = palm.generate_text(\n","    model=model,\n","    prompt=prompt,\n","    temperature=0,\n","    # The maximum length of the response\n","    max_output_tokens=200,\n",")\n","\n","print(completion.result)"],"metadata":{"id":"DFnfJtYbXd_E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694762828111,"user_tz":-330,"elapsed":2273,"user":{"displayName":"Gopal Sharma","userId":"12839894256006393174"}},"outputId":"339bf070-8e13-45f0-846c-a094b40a8bc1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Imagine a coin. When you flip it, it can land on heads or tails. But what if I told you that a quantum coin could land on heads and tails at the same time? That's what quantum computing is all about. It's a new way of computing that uses the power of quantum mechanics to solve problems that are impossible for classical computers.\n","\n","One of the most important things to understand about quantum computing is that it's not just a faster way of doing things. It's a completely different way of thinking about computers. Classical computers use bits, which can be either 0 or 1. But quantum computers use qubits, which can be 0, 1, or both at the same time. This is called superposition, and it's one of the things that makes quantum computing so powerful.\n","\n","So how can quantum computing be used to solve problems? Well, one example is Shor's algorithm. Shor's algorithm is a quantum\n"]}]},{"cell_type":"markdown","source":["## Custom Chatbot"],"metadata":{"id":"8NU1b3f5kdkc"}},{"cell_type":"markdown","source":["### Text Summarizer"],"metadata":{"id":"x0pzfK-gkzJU"}},{"cell_type":"code","source":["def foo(numbers):\n","    for i in range(len(numbers)):\n","        numbers[i] += 1\n","        my_list = [1, 2, 3, 4]\n","\n","my_list = [1, 2, 3, 4]\n","foo(my_list)\n","print(my_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o4dSsnjd9DvI","executionInfo":{"status":"ok","timestamp":1695912244076,"user_tz":-330,"elapsed":7,"user":{"displayName":"Gopal Sharma","userId":"12839894256006393174"}},"outputId":"9b849ba8-a841-4504-a52b-1d8e1ee93b50"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[2, 3, 4, 5]\n"]}]},{"cell_type":"code","source":["!pip install pypdf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6krlXbIVwsZe","executionInfo":{"status":"ok","timestamp":1694762853336,"user_tz":-330,"elapsed":6606,"user":{"displayName":"Gopal Sharma","userId":"12839894256006393174"}},"outputId":"74c0d0e7-8a80-4eb0-c8f4-bd554cdaf033"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pypdf\n","  Downloading pypdf-3.16.0-py3-none-any.whl (276 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/276.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/276.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.0/276.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pypdf\n","Successfully installed pypdf-3.16.0\n"]}]},{"cell_type":"code","source":["from pypdf import PdfReader"],"metadata":{"id":"P6-zH35Dw0Xm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"ptCfCdRprdOH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694762875810,"user_tz":-330,"elapsed":19915,"user":{"displayName":"Gopal Sharma","userId":"12839894256006393174"}},"outputId":"dfeb8b88-c2f9-4659-b2a4-36e5b1c52bbb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["directory = '/content/drive/MyDrive/1-Build-a-Chatbot/'\n","filename  = 'Attention-Is-All-You-Need.pdf'\n","# filename  = 'Art-of-War.pdf'"],"metadata":{"id":"n6d42reCXq7w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# creating a pdf file object\n","pdfFileObject = open(directory+filename, 'rb')\n","# creating a pdf reader object\n","pdfReader = PdfReader(pdfFileObject)\n","text=[]\n","summary=' '\n","#Storing the pages in a list\n","for i in range(0,len(pdfReader.pages)):\n","  # creating a page object\n","  pageObj = pdfReader.pages[i].extract_text()\n","  pageObj= pageObj.replace('\\t\\r','')\n","  pageObj= pageObj.replace('\\xa0','')\n","  # extracting text from page\n","  text.append(pageObj)"],"metadata":{"id":"gYpNlLqcZVyw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Merge multiple page - to reduce API Calls\n","def join_elements(lst, chars_per_element):\n","    new_lst = []\n","    for i in range(0, len(lst), chars_per_element):\n","        new_lst.append(''.join(lst[i:i+chars_per_element]))\n","    return new_lst\n","\n","# Option to keep x elements per list element\n","new_text = join_elements(text, 3)\n","\n","print(f\"Original Pages = \",len(text))\n","print(f\"Compressed Pages = \",len(new_text))"],"metadata":{"id":"0y8iM7trjKdM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694762878206,"user_tz":-330,"elapsed":6,"user":{"displayName":"Gopal Sharma","userId":"12839894256006393174"}},"outputId":"8d28050f-7e0e-46a7-c4a5-edb0835ab8e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Pages =  15\n","Compressed Pages =  5\n"]}]},{"cell_type":"code","source":["def get_completion(prompt):\n","  completion = palm.generate_text(model=model,\n","                                  prompt=prompt,\n","                                  temperature=0,\n","                                  # The maximum length of the response\n","                                  max_output_tokens=200,\n","                                  )\n","  return completion.result"],"metadata":{"id":"AJ_lIoBzX267"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["summary = \"\"\n","for i in range(len(new_text)):\n","  prompt =f\"\"\"\n","  Your task is to act as a Text Summariser.\n","  I'll give you text from  pages of a book from beginning to end.\n","  And your job is to summarise text from these pages in less than 100 words.\n","  Don't be conversational. I need a plain 100 word answer.\n","  Text is shared below, delimited with triple backticks:\n","  ```{text[i]}```\n","  \"\"\"\n","  try:\n","    response = get_completion(prompt)\n","  except:\n","    response = get_completion(prompt)\n","  print(response)\n","  summary= f\"{summary} {response}\\n\\n\"\n","  # result.append(response)\n","  time.sleep(19)  #You can query the model only 3 times in a minute for free, so we need to put some delay"],"metadata":{"id":"CxpOAcNuZV3y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694763645515,"user_tz":-330,"elapsed":102932,"user":{"displayName":"Gopal Sharma","userId":"12839894256006393174"}},"outputId":"a2edf1a5-b483-43c4-c1cf-a75585dd2dc8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Transformer is a new neural network architecture for sequence transduction tasks. It is based on attention mechanisms and does not use recurrence or convolutions. It achieves state-of-the-art results on machine translation and constituency parsing tasks.\n","Transformer is a new neural network architecture for sequence transduction tasks. It eschews recurrence and instead relies entirely on an attention mechanism to draw global dependencies between input and output.\n","Transformer model consists of encoder and decoder stacks. Encoder stack has 6 identical layers, each with 2 sub-layers: multi-head self-attention and position-wise fully connected feed-forward network. Decoder stack has 3 sub-layers: multi-head self-attention, multi-head attention over the output of the encoder stack and position-wise fully connected feed-forward network.\n","Attention is a mechanism that allows an AI model to focus on specific parts of a input sequence.\n","It is used in the Transformer model to improve performance on a variety of natural language processing tasks.\n","Transformer model consists of an encoder and decoder, each containing a stack of identical layers.\n","The encoder layers contain multi-head attention and feed-forward networks. The decoder layers\n","contain multi-head attention, feed-forward networks and an additional attention layer that attends\n","to the encoder output.\n"]}]},{"cell_type":"code","source":["with open(directory +'/palm_api_summary.txt',\n","          'w') as out:\n","  out.write(summary)"],"metadata":{"id":"9SilyVEiX29Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Mock Interview"],"metadata":{"id":"X7egGmm2lylv"}},{"cell_type":"code","source":["# Build a Chatbot that takes a Mock Interview\n","# For a specific Job Role, provided as input by End-User."],"metadata":{"id":"kAV64iIplwPf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### AI Teacher"],"metadata":{"id":"ww6orEprm-O0"}},{"cell_type":"code","source":["# This AI Teacher explains you topics in ELI-X level\n","# Where \"X\" is the age-appropriate learner level."],"metadata":{"id":"ktxJSTM-nABu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Code Reviewer"],"metadata":{"id":"9r81CAOhod28"}},{"cell_type":"code","source":["# AI helper that generates comprehensive review that cover code\n","# Clarity, structure, efficiency, adherence\n","# To best practices, and maintainability."],"metadata":{"id":"ItFGGhvQogCs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Chatbot w/ ChatGPT API"],"metadata":{"id":"0Sz-Ga9lsdZY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xc7SQDTeQLr2"},"outputs":[],"source":["!pip install openai PyPDF2"]},{"cell_type":"code","source":["import openai\n","import PyPDF2\n","import os\n","import pandas as pd\n","import time"],"metadata":{"id":"H7TURFkhRzzy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["filepath= \"/content/drive/MyDrive/1-Build-a-Chatbot/Attention-Is-All-You-Need.pdf\"\n","openai.api_key  = \"Insert-Key-Here\""],"metadata":{"id":"5j8ORkSRR8Hp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n","  messages = [{\"role\": \"user\", \"content\": prompt}]\n","  response = openai.ChatCompletion.create(\n","     model=model,\n","     messages=messages,\n","     temperature=0, # this is the degree of randomness of the model's output\n","  )\n","  return response.choices[0].message[\"content\"]"],"metadata":{"id":"Se1RoCM8R8OK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt =f\"\"\"Who is the Prime Minister of India?\"\"\"\n","response = get_completion(prompt)\n","print(response)\n","time.sleep(19)  #You can query the model only 3 times in a minute for free, so we need to put some delay"],"metadata":{"id":"8wUSQ_gqTbtM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# creating a pdf file object\n","pdfFileObject = open(filepath, 'rb')\n","# creating a pdf reader object\n","pdfReader = PyPDF2.PdfReader(pdfFileObject)\n","text=[]\n","summary=' '\n","#Storing the pages in a list\n","for i in range(0,len(pdfReader.pages)):\n","  # creating a page object\n","  pageObj = pdfReader.pages[i].extract_text()\n","  pageObj= pageObj.replace('\\t\\r','')\n","  pageObj= pageObj.replace('\\xa0','')\n","  # extracting text from page\n","  text.append(pageObj)"],"metadata":{"id":"PIW2BOdvRz23"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(len(text)):\n","  prompt =f\"\"\"\n","  Your task is to extract relevant information from a text on the page of a book.\n","  This information will be used to create a book summary.\n","  Extract relevant information from the following text, which is delimited with triple backticks.\\\n","  Be sure to preserve the important details.\n","  Text: ```{text[i]}```\n","  \"\"\"\n","  try:\n","    response = get_completion(prompt)\n","  except:\n","    response = get_completion(prompt)\n","  print(response)\n","  summary= summary+' ' +response +'\\n\\n'\n","  result.append(response)\n","  time.sleep(19)  #You can query the model only 3 times in a minute for free, so we need to put some delay"],"metadata":{"id":"iDmLL0C2S35Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('/content/drive/MyDrive/1-Build-a-Chatbot/summary.txt',\n","          'w') as out:\n","  out.write(summary)"],"metadata":{"id":"x538eUQyTHhY"},"execution_count":null,"outputs":[]}]}